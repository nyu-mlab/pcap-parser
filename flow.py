"""
Processes and aggregates network flow data from a CSV file generated by the parse.py script.

This script is intended to be run after parse.py, which produces a CSV file with detailed flow-level network traffic data.
Includes hostname information from DNS, TLS, and DHCP. The script filters network traffic for TCP, TLSv1.2, UDP, TLS, and DNS, groups packets into flows based on connection details, calculates flow statistics, and extracts initial hostnames and DHCP hostnames. The aggregated data is then saved to a new CSV file.

Usage:
    python flow.py <input_csv_file> <output_csv_file>

Example:
    python flow.py output_from_parse.csv aggregated_flows.csv

Note:
    Requires pandas and tldextract. Platform-independent.
"""

import pandas as pd
import sys
import tldextract

def extract_main_domain(hostname):
    try:
        extracted = tldextract.extract(str(hostname))
        return f"{extracted.domain}.{extracted.suffix}" if extracted.suffix else ''
    except:
        return None

def get_src_port(row):
    return row['tcp.srcport'] if pd.notna(row['tcp.srcport']) else row['udp.srcport']

def get_dst_port(row):
    return row['tcp.dstport'] if pd.notna(row['tcp.dstport']) else row['udp.dstport']

def process_pcap_data(input_csv, output_csv):
    df = pd.read_csv(input_csv)
    df['frame.time_epoch'] = pd.to_datetime(df['frame.time_epoch'], unit='s', errors='coerce')

    df = df[df['_ws.col.protocol'].isin(['TCP', 'TLSv1.2', 'UDP', 'TLS', 'DNS'])]

    # Combine ports
    df['src_port'] = df.apply(get_src_port, axis=1)
    df['dst_port'] = df.apply(get_dst_port, axis=1)

    # Drop if missing core fields
    df = df.dropna(subset=['ip.src', 'ip.dst', 'src_port', 'dst_port', '_ws.col.protocol'])

    # Sort
    df = df.sort_values(by=[
        'ip.src', 'ip.dst', 'src_port', 'dst_port',
        '_ws.col.protocol', 'frame.time_epoch'
    ])

    # Inter-arrival time
    df['inter_arrival_time'] = df.groupby([
        'ip.src', 'ip.dst', 'src_port', 'dst_port', '_ws.col.protocol'
    ])['frame.time_epoch'].diff().dt.total_seconds()

    # Domain extraction
    df['src_main_domain'] = df['src_hostname'].apply(extract_main_domain)
    df['dst_main_domain'] = df['dst_hostname'].apply(extract_main_domain)

    # Group into flows
    grouped = df.groupby([
        'ip.src', 'ip.dst', 'src_port', 'dst_port', '_ws.col.protocol'
    ])

    flows = grouped.agg(
        start_ts=('frame.time_epoch', 'min'),
        end_ts=('frame.time_epoch', 'max'),
        byte_count=('frame.len', 'sum'),
        packet_count=('frame.len', 'size'),
        avg_inter_arrival_time=('inter_arrival_time', 'mean'),
        src_hostname=('src_hostname', 'first'),
        dst_hostname=('dst_hostname', 'first'),
        dhcp_hostname=('dhcp_hostname', 'first'),
        src_main_domain=('src_main_domain', 'first'),
        dst_main_domain=('dst_main_domain', 'first'),
        user_agent_info=('http.user_agent', 'first'),
        oui_vendor=('eth.src.oui_resolved', 'first')
    ).reset_index()

    flows = flows[[
        'start_ts', 'end_ts', 'ip.src', 'ip.dst',
        'src_port', 'dst_port', '_ws.col.protocol',
        'byte_count', 'packet_count', 'avg_inter_arrival_time',
        'src_hostname', 'dst_hostname', 'dhcp_hostname',
        'src_main_domain', 'dst_main_domain',
        'user_agent_info', 'oui_vendor'
    ]]

    flows.to_csv(output_csv, index=False)
    print(f"[âœ“] Done. Saved {len(flows)} flows to {output_csv}")

def main():
    if len(sys.argv) != 3:
        print("Usage: python flow.py <input_csv_file> <output_csv_file>")
        sys.exit(1)

    input_csv_file = sys.argv[1]
    output_csv_file = sys.argv[2]
    process_pcap_data(input_csv_file, output_csv_file)

if __name__ == "__main__":
    main()
