"""
Processes and aggregates network flow data from a CSV file generated by the parse.py script.

This script is intended to be run after parse.py, which produces a CSV file with detailed network traffic data.
The script filters network traffic for TCP, TLSv1.2, and UDP, and groups packets into flows based on connection details, calculates flow statistics, and extracts initial hostnames. The aggregated data is then saved to a new CSV file.

Usage:
    python flow.py <input_csv_file> <output_csv_file>

Example:
    python flow.py output_from_parse.csv aggregated_flows.csv

Note:
    The script is platform-independent but requires Python and pandas to be installed. Make sure file paths and permissions are correctly configured according to your operating system's requirements.
"""

import pandas as pd
import sys
import os
import tldextract


def extract_main_domain(hostname):
    """
    Extracts the main domain from a hostname using tldextract.

    Args:
        hostname (str): The hostname to extract the domain from.

    Returns:
        str: The extracted main domain, or None if extraction fails.
    """
    if not hostname:  # Handle empty or None values
        return None
    try:
        extracted = tldextract.TLDExtract(cache_dir=False)(hostname)  # Disable caching
        return f"{extracted.domain}.{extracted.suffix}" if extracted.suffix else None
    except Exception:
        return None


def process_pcap_data(input_csv, output_csv):
    """
    Processes the input CSV, aggregates flow data, and writes the result to an output CSV.

    Args:
        input_csv (str): Path to the input CSV file.
        output_csv (str): Path to the output CSV file.
    """
    # Check if the input file is empty
    if os.stat(input_csv).st_size == 0:
        print(f"Input file {input_csv} is empty.")
        pd.DataFrame().to_csv(output_csv, index=False)  # Write an empty output file
        return

    # Read the input CSV
    df = pd.read_csv(input_csv)

    # Convert timestamps to datetime
    df['frame.time_epoch'] = pd.to_datetime(df['frame.time_epoch'], unit='s')

    # Filter out non-TCP, non-TLSv1.2, and non-UDP Protocols
    df = df[df['_ws.col.Protocol'].isin(['TCP', 'TLSv1.2', 'UDP'])]
    if df.empty:
        print(f"No rows match the specified Protocols in {input_csv}.")
        pd.DataFrame().to_csv(output_csv, index=False)
        return

    # Sort by grouping columns and timestamp
    df = df.sort_values(by=['ip.src', 'ip.dst', 'tcp.srcport', 'tcp.dstport', 'udp.srcport', 'udp.dstport', '_ws.col.Protocol', 'frame.time_epoch'])

    # Calculate inter-arrival times
    df['inter_arrival_time'] = df.groupby(['ip.src', 'ip.dst', 'tcp.srcport', 'tcp.dstport', 'udp.srcport', 'udp.dstport', '_ws.col.Protocol'])['frame.time_epoch'].diff().dt.total_seconds()

    # Extract main domains from hostnames
    df['src_main_domain'] = df['src_hostname'].apply(extract_main_domain)
    df['dst_main_domain'] = df['dst_hostname'].apply(extract_main_domain)

    # Aggregate data for each flow
    grouped = df.groupby(['ip.src', 'ip.dst', 'tcp.srcport', 'tcp.dstport', 'udp.srcport', 'udp.dstport', '_ws.col.Protocol'])
    flows = grouped.agg(
        start_ts=('frame.time_epoch', 'min'),
        end_ts=('frame.time_epoch', 'max'),
        byte_count=('frame.len', 'sum'),
        packet_count=('frame.len', 'size'),
        avg_inter_arrival_time=('inter_arrival_time', 'mean'),
        src_hostname=('src_hostname', 'first'),
        dst_hostname=('dst_hostname', 'first'),
        src_main_domain=('src_main_domain', 'first'),
        dst_main_domain=('dst_main_domain', 'first')
    )
    flows.reset_index(inplace=True)

    # Reorder columns for output
    columns_order = [
        'start_ts', 'end_ts', 'ip.src', 'ip.dst',
        'tcp.srcport', 'tcp.dstport', 'udp.srcport', 'udp.dstport',
        '_ws.col.Protocol', 'byte_count', 'packet_count',
        'avg_inter_arrival_time', 'src_hostname', 'dst_hostname',
        'src_main_domain', 'dst_main_domain'
    ]
    flows = flows[columns_order]

    # Write the aggregated data to output CSV
    flows.to_csv(output_csv, index=False)


def main():
    """
    Main entry point for the script.
    """
    if len(sys.argv) != 3:
        print("Usage: python flow.py <input_csv_file> <output_csv_file>")
        sys.exit(1)

    input_csv_file = sys.argv[1]
    output_csv_file = sys.argv[2]

    process_pcap_data(input_csv_file, output_csv_file)

if __name__ == "__main__":
    main()